{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:40.983292Z",
     "start_time": "2022-01-30T02:09:39.730466Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:41.002887Z",
     "start_time": "2022-01-30T02:09:40.985162Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Current device: 0\n",
      "Device: cuda:0\n",
      "Device count: 1\n",
      "Device name: GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.cuda.current_device()\n",
    "device = torch.device(\"cuda:0\" if available else \"cpu\")\n",
    "device_count = torch.cuda.device_count() \n",
    "device_name =  torch.cuda.get_device_name(0)\n",
    "\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Device count: {device_count}')\n",
    "print(f'Device name: {device_name}')\n",
    "\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:41.100800Z",
     "start_time": "2022-01-30T02:09:41.004363Z"
    }
   },
   "outputs": [],
   "source": [
    "# (Adapted) Code from PyTorch's Resnet impl: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer = None,\n",
    "        use_final_relu = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        \n",
    "        # BK: Force last layers back to inplanes\n",
    "        self.conv3 = conv1x1(width, inplanes)\n",
    "        self.bn3 = norm_layer(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.use_final_relu = use_final_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        #out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        #out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        #out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        if self.use_final_relu:\n",
    "            out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:41.233429Z",
     "start_time": "2022-01-30T02:09:41.103858Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = tuple([-1] + list(shape))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.reshape(x, self.shape)\n",
    "\n",
    "def dense_backbone(shape, network_width):\n",
    "    input_width = shape[0] * shape[1] * shape[2]\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_width, network_width),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(network_width, input_width),\n",
    "        Reshape(shape)\n",
    "    )\n",
    "\n",
    "def bottleneck_backbone(planes):\n",
    "    return nn.Sequential(\n",
    "        Bottleneck(1, planes),\n",
    "        Bottleneck(1, planes),\n",
    "    )\n",
    "\n",
    "mask = {}\n",
    "mask_device = {}\n",
    "def checkerboard_mask(shape, to_device=True):\n",
    "    global mask, mask_device\n",
    "    if shape not in mask:\n",
    "        mask[shape] = 1 - np.indices(shape).sum(axis=0) % 2\n",
    "        mask[shape] = torch.Tensor(mask[shape])\n",
    "        \n",
    "    if to_device and shape not in mask_device:\n",
    "        mask_device[shape] = mask[shape].to(device)\n",
    "        \n",
    "    return mask_device[shape] if to_device else mask[shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:41.324562Z",
     "start_time": "2022-01-30T02:09:41.236571Z"
    }
   },
   "outputs": [],
   "source": [
    "class NormalizingFlowMNist(nn.Module):\n",
    "    EPSILON = 1e-7\n",
    "    \n",
    "    def __init__(self, num_coupling, planes):\n",
    "        super(NormalizingFlowMNist, self).__init__()\n",
    "        self.num_coupling = num_coupling\n",
    "        self.shape = (1, 28, 28)\n",
    "        \n",
    "        self.planes = planes\n",
    "        self.s = nn.ModuleList([bottleneck_backbone(planes) \n",
    "                                for x in range(num_coupling)])\n",
    "        self.t = nn.ModuleList([bottleneck_backbone(planes)\n",
    "                                for x in range(num_coupling)])\n",
    "        \n",
    "        # Learnable scaling parameters for outputs of S\n",
    "        self.s_scale = nn.ParameterList([torch.nn.Parameter(torch.randn(self.shape)) \n",
    "                                         for x in range(num_coupling)])\n",
    "        for i in range(num_coupling):\n",
    "            self.s_scale[i].requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if model.training:\n",
    "            s_vals = []\n",
    "            for i in range(self.num_coupling):\n",
    "                mask = checkerboard_mask(self.shape)\n",
    "                mask = mask if i % 2 == 0 else (1 - mask)\n",
    "               \n",
    "                t = self.t[i](mask * x)\n",
    "                s = (self.s_scale[i]) * torch.tanh(self.s[i](mask * x))\n",
    "                y = mask * x + (1 - mask) * (x * torch.exp(s) + t)\n",
    "                s_vals.append(mask * s)\n",
    "                \n",
    "                x = y\n",
    "\n",
    "            # Return outputs and vars needed for determinant\n",
    "            return y, torch.cat(s_vals)\n",
    "        else:\n",
    "            y = x\n",
    "            for i in reversed(range(self.num_coupling)):\n",
    "                mask = checkerboard_mask(self.shape)\n",
    "                mask = mask if i % 2 == 0 else (1 - mask)\n",
    "               \n",
    "                t = self.t[i](mask * y)\n",
    "                s = (mask * self.s_scale[i]) * torch.tanh(self.s[i](mask * y))\n",
    "                x = mask * y + (1 - mask)((y - t) * torch.exp(-s + EPSILON))\n",
    "                \n",
    "                y = x\n",
    "                \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:09:41.458192Z",
     "start_time": "2022-01-30T02:09:41.327207Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(y, s, batch_size):\n",
    "    # -log(zero-mean gaussian) + log determinant\n",
    "    # -log p_x = log(pz(f(x))) + log(det(\\partial f/\\partial x))\n",
    "    # -log p_x = 0.5 * y**2 + s1 + s2 + ...\n",
    "    logpx = -torch.sum(0.5 * y**2)\n",
    "    det = torch.sum(s)\n",
    "    ret = -(logpx + det)\n",
    "    return torch.div(ret, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:13:51.693073Z",
     "start_time": "2022-01-30T02:13:51.681194Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, report_iters=10, num_pixels=28*28):\n",
    "    size = len(dataloader)\n",
    "    prev = []\n",
    "    for batch, (X, _) in enumerate(dataloader):\n",
    "        # Transfer to GPU\n",
    "        X = X.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        y, s = model(X)\n",
    "        loss = loss_fn(y, s, batch_size)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        prev = [(name, x, x.grad) for name, x in model.named_parameters(recurse=True)]\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % report_iters == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:.2f}; {loss / num_pixels / np.log(2):>.2f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, num_pixels=28*28):\n",
    "    size = len(dataloader)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, _ in dataloader:\n",
    "            X = X.to(device)\n",
    "            y, s = model(X)\n",
    "            test_loss += loss_fn(y, s, batch_size)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:.2f}; {test_loss / num_pixels / np.log(2):.2f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNist Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:13:52.453016Z",
     "start_time": "2022-01-30T02:13:52.448182Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(x):\n",
    "    # Convert back to integer values\n",
    "    x = x * 255.\n",
    "    \n",
    "    # Add random uniform [0, 1] noise to get a proper likelihood estimate\n",
    "    # https://bjlkeng.github.io/posts/a-note-on-using-log-likelihood-for-generative-models/\n",
    "    x = x + torch.rand(x.shape)\n",
    "    \n",
    "    # Apply transform to deal with boundary effects (see realNVP paper)\n",
    "    x = torch.logit(0.05 + 0.90 * x / 256)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:13:52.692606Z",
     "start_time": "2022-01-30T02:13:52.652887Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('data', train=True, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Lambda(pre_process)\n",
    "                               ]))\n",
    "test_dataset = datasets.MNIST('data', train=False, download=True,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Lambda(pre_process),\n",
    "                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T02:14:43.879488Z",
     "start_time": "2022-01-30T02:13:52.877673Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2991.84; 5.51  [    0/  600]\n",
      "loss: 555.46; 1.02  [   10/  600]\n",
      "loss: 482.01; 0.89  [   20/  600]\n",
      "loss: 369.45; 0.68  [   30/  600]\n",
      "loss: 350.66; 0.65  [   40/  600]\n",
      "loss: 349.23; 0.64  [   50/  600]\n",
      "loss: 402.66; 0.74  [   60/  600]\n",
      "loss: 288.61; 0.53  [   70/  600]\n",
      "loss: 345.52; 0.64  [   80/  600]\n",
      "loss: 265.58; 0.49  [   90/  600]\n",
      "loss: 270.46; 0.50  [  100/  600]\n",
      "loss: 280.42; 0.52  [  110/  600]\n",
      "loss: 232.31; 0.43  [  120/  600]\n",
      "loss: 269.43; 0.50  [  130/  600]\n",
      "loss: 219.72; 0.40  [  140/  600]\n",
      "loss: 143.88; 0.26  [  150/  600]\n",
      "loss: 164.26; 0.30  [  160/  600]\n",
      "loss: 110.23; 0.20  [  170/  600]\n",
      "loss: 108.00; 0.20  [  180/  600]\n",
      "loss: 76.59; 0.14  [  190/  600]\n",
      "loss: 110.35; 0.20  [  200/  600]\n",
      "loss: 57.21; 0.11  [  210/  600]\n",
      "loss: 81.44; 0.15  [  220/  600]\n",
      "loss: 147.58; 0.27  [  230/  600]\n",
      "loss: 97.08; 0.18  [  240/  600]\n",
      "loss: 41.22; 0.08  [  250/  600]\n",
      "loss: 52.70; 0.10  [  260/  600]\n",
      "loss: 19.86; 0.04  [  270/  600]\n",
      "loss: 42.81; 0.08  [  280/  600]\n",
      "loss: 0.56; 0.00  [  290/  600]\n",
      "loss: -4.56; -0.01  [  300/  600]\n",
      "loss: -20.39; -0.04  [  310/  600]\n",
      "loss: 2.00; 0.00  [  320/  600]\n",
      "loss: 16.26; 0.03  [  330/  600]\n",
      "loss: -66.71; -0.12  [  340/  600]\n",
      "loss: -26.05; -0.05  [  350/  600]\n",
      "loss: -122.61; -0.23  [  360/  600]\n",
      "loss: -40.96; -0.08  [  370/  600]\n",
      "loss: -110.30; -0.20  [  380/  600]\n",
      "loss: -82.61; -0.15  [  390/  600]\n",
      "loss: -73.08; -0.13  [  400/  600]\n",
      "loss: -98.06; -0.18  [  410/  600]\n",
      "loss: -59.06; -0.11  [  420/  600]\n",
      "loss: -129.41; -0.24  [  430/  600]\n",
      "loss: -140.29; -0.26  [  440/  600]\n",
      "loss: -119.61; -0.22  [  450/  600]\n",
      "loss: -167.83; -0.31  [  460/  600]\n",
      "loss: -148.28; -0.27  [  470/  600]\n",
      "loss: -95.16; -0.18  [  480/  600]\n",
      "loss: -190.91; -0.35  [  490/  600]\n",
      "loss: -192.03; -0.35  [  500/  600]\n",
      "loss: -185.22; -0.34  [  510/  600]\n",
      "loss: -229.94; -0.42  [  520/  600]\n",
      "loss: -168.85; -0.31  [  530/  600]\n",
      "loss: -207.67; -0.38  [  540/  600]\n",
      "loss: -211.55; -0.39  [  550/  600]\n",
      "loss: -210.68; -0.39  [  560/  600]\n",
      "loss: -286.14; -0.53  [  570/  600]\n",
      "loss: -268.70; -0.49  [  580/  600]\n",
      "loss: -259.06; -0.48  [  590/  600]\n",
      "Test Error: \n",
      " Avg loss: -230.89; -0.42 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "\n",
    "model = NormalizingFlowMNist(3, 64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) #shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,  shuffle=False) #shuffle=True)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022-01-29\n",
    "\n",
    "* Getting lots of NaNs -- debugged a bunch of things:\n",
    "    * Removed Resnet\n",
    "    * Removed exp()\n",
    "    * Made forward pass a simple feedforward\n",
    "* But it looks like issue is the data???    \n",
    "    * The stupid paper said the transform should be `logit(alpha + (1-alpha)*x/256)`...\n",
    "    * Data is originally in [0,1] (pytorch dataset)\n",
    "    * Convert back to pixels multiply by 255\n",
    "    * Add jitter to get upper bound on bits per pixel (see my post)\n",
    "    * Range is now [0, 256]\n",
    "    * Suggested alpha=0.05 (I had a bug and used 0.5)\n",
    "    * But that gets you really close to 256 (jitter is always less than 1.0 though) e.g.i logit(0.05 + 0.95 * ~255.99/256) ~= \\inf!\n",
    "    * Instead, I used this `logit(alpha + (1-alpha - 0.05)*x/256)`, which is symmetrical...\n",
    "    \n",
    "NEXT STEPS:\n",
    "* So things look good now, except that I get a negative loss, which shouldn't happen (after applying jitter)???\n",
    "    * It's because I need a new uniform noise sample per EPOCH???\n",
    "    * Or is it because I'm using continuous variables on the output?  So maybe I just need to measure this \"loss\" when I reverse the network?  \n",
    "        * It's probably this... if it's a continuous output, the log density surely doesn't need to be positive (vs. if I were directly outputting pixel values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
