{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import keras\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "ftrain = H5PYDataset(\"../../data/cifar10/cifar10.hdf5\", which_sets=('train',))\n",
    "X_train, y_train = ftrain.get_data(ftrain.open(), slice(0, ftrain.num_examples))\n",
    "X_train = np.moveaxis(X_train[:], 1, 3) / 255.\n",
    "\n",
    "ftest = H5PYDataset(\"../../data/cifar10/cifar10.hdf5\", which_sets=('test',))\n",
    "X_test, y_test = ftest.get_data(ftest.open(), slice(0, ftest.num_examples))\n",
    "X_test = np.moveaxis(X_test[:], 1, 3) / 255.\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols, img_chns = 32, 32, 3\n",
    "\n",
    "# number of convolutional filters to use\n",
    "num_classes = 10\n",
    "\n",
    "batch_size = 100\n",
    "original_img_size = (img_rows, img_cols, img_chns)\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with sample_size: 1000\n",
      "\n",
      " * Accuracy: 43.4 %\n",
      " * Fit time elapsed: 64.2s\n",
      "Fitting with sample_size: 2000\n",
      "\n",
      " * Accuracy: 48.4 %\n",
      " * Fit time elapsed: 98.7s\n",
      "Fitting with sample_size: 5000\n",
      "\n",
      " * Accuracy: 61.0 %\n",
      " * Fit time elapsed: 231.8s\n",
      "Fitting with sample_size: 10000\n",
      "\n",
      " * Accuracy: 67.3 %\n",
      " * Fit time elapsed: 346.6s\n",
      "Fitting with sample_size: 25000\n",
      "\n",
      " * Accuracy: 76.8 %\n",
      " * Fit time elapsed: 601.1s\n",
      "Fitting with sample_size: 50000\n",
      "\n",
      " * Accuracy: 80.7 %\n",
      " * Fit time elapsed: 921.4s\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample_size in [1000, 2000, 5000, 10000, 25000, 50000]:\n",
    "    start = time.time()\n",
    "    print('Fitting with sample_size: {}'.format(sample_size))\n",
    "   \n",
    "    if sample_size < len(X_train):\n",
    "        sss = StratifiedShuffleSplit(n_splits=2, test_size=sample_size / len(X_train), random_state=0)\n",
    "        _, index = sss.split(X_train, y_train)\n",
    "        X, y = X_train[index[1]], y_train[index[1]]\n",
    "    else:\n",
    "        X, y = X_train, y_train\n",
    "   \n",
    "    y = np_utils.to_categorical(y)\n",
    "    model = create_model()\n",
    "    model.fit(X, y, shuffle=True, \n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              verbose=0,\n",
    "              callbacks=[TQDMNotebookCallback(), \n",
    "                         EarlyStopping(monitor='loss', min_delta=0.01, patience=50)])\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(' * Accuracy: %.1f %%' % (100. * score))\n",
    "    print(' * Fit time elapsed: %.1fs' % elapsed)\n",
    "    results.append({'sample_size': sample_size, 'accuracy': score, 'time': elapsed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4335</td>\n",
       "      <td>1000</td>\n",
       "      <td>64.155168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4844</td>\n",
       "      <td>2000</td>\n",
       "      <td>98.667964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6097</td>\n",
       "      <td>5000</td>\n",
       "      <td>231.792324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6731</td>\n",
       "      <td>10000</td>\n",
       "      <td>346.644258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7675</td>\n",
       "      <td>25000</td>\n",
       "      <td>601.067277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8073</td>\n",
       "      <td>50000</td>\n",
       "      <td>921.351678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  sample_size        time\n",
       "0    0.4335         1000   64.155168\n",
       "1    0.4844         2000   98.667964\n",
       "2    0.6097         5000  231.792324\n",
       "3    0.6731        10000  346.644258\n",
       "4    0.7675        25000  601.067277\n",
       "5    0.8073        50000  921.351678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "display(df)\n",
    "df.to_csv('cnn_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
