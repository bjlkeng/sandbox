{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jsonlines\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "system_prompt = \"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly. The assistant will attempt to give a response that is concise but ensures that all the key points are included when relevant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_chat(message, temperature, seed, model, system_prompt=system_prompt, client=client):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": system_prompt\n",
    "            }, \n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message,\n",
    "            },\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    # Extract the response from the chat completion\n",
    "    message = chat_completion.choices[0].message.content\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of a big document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a jsonl file with jsonl library \n",
    "def read_jsonl(filepath):\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "        posts = []\n",
    "        for obj in reader:\n",
    "            posts.append(json.dumps(obj))\n",
    "\n",
    "    return '\\n\\n'.join(posts)\n",
    "\n",
    "blog_posts = read_jsonl('data/blog_trim.jsonl')\n",
    "blog_posts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_summarize_experiment(data, seed, temperature, model, iterations=10):\n",
    "    entries = []\n",
    "    for i in range(iterations):\n",
    "        print(f'Iteration {i+1}')\n",
    "        prompt = \"Summarize the following: \" + data\n",
    "        response = complete_chat(prompt, \n",
    "                                 seed=seed, \n",
    "                                 temperature=temperature, \n",
    "                                 model=model if i > 0 else 'gpt-4o')\n",
    "        entry = {\n",
    "            \"iteration\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": seed,\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"response\": response,\n",
    "            \"length\": len(response),\n",
    "        }\n",
    "        #Log as table in wandb\n",
    "        wandb.log(entry)\n",
    "\n",
    "        print(f'* data: {len(data)}')\n",
    "        print(f'* len: {entry[\"length\"]}')\n",
    "        print('')\n",
    "\n",
    "        data = response\n",
    "        entries.append(entry)\n",
    "\n",
    "    return pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "iterations = 50\n",
    "\n",
    "def make_run_name(config):\n",
    "    return f\"run-{config['model']}_{config['seed']}_{config['temperature']}\"\n",
    "\n",
    "dfs = []\n",
    "for temperature in [0.0, 0.5, 1.0, 2.0]:\n",
    "    for model in ['gpt-4o', 'gpt-3.5-turbo']:\n",
    "        config = {\n",
    "            \"seed\": seed,\n",
    "            \"temperature\": temperature,\n",
    "            \"model\": model,\n",
    "            \"iterations\": iterations,\n",
    "        }\n",
    "\n",
    "        wandb.init(project=\"llm_fixed_point\",\n",
    "                   name=make_run_name(config),\n",
    "                   config=config)\n",
    "\n",
    "        data = blog_posts\n",
    "        df = run_summarize_experiment(data, **config)\n",
    "        dfs.append((config, df))\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        # wait 30 seconds to avoid rate limiting\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([x for _, x in dfs])\n",
    "df.head()\n",
    "\n",
    "df.to_csv('data/summarize_blog_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_csv('data/summarize_blog_posts.csv')\n",
    "\n",
    "def compare(df, model, temperature):\n",
    "    df = df[(df.model == model) & (df.temperature == temperature)]['response']\n",
    "    print(df.iloc[0])\n",
    "    print('#' * 100)\n",
    "    print(df.iloc[-1])\n",
    "\n",
    "compare(df=read_df, model='gpt-4o', temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize List of Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_list_summarize_experiment(data, seed, temperature, model, prompt, iterations=10):\n",
    "    entries = []\n",
    "    for i in range(iterations):\n",
    "        print(f'Iteration {i+1}')\n",
    "        prompt = prompt + data\n",
    "        response = complete_chat(prompt, \n",
    "                                 seed=seed, \n",
    "                                 temperature=temperature, \n",
    "                                 model=model if i > 0 else 'gpt-4o')\n",
    "        entry = {\n",
    "            \"iteration\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": seed,\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature,\n",
    "            \"response\": response,\n",
    "            \"length\": len(response),\n",
    "            \"lines\": len(response.split('\\n')),\n",
    "        }\n",
    "        #Log as table in wandb\n",
    "        wandb.log(entry)\n",
    "\n",
    "        print(f'* data: {len(data)}')\n",
    "        print(f'* len: {entry[\"length\"]}')\n",
    "        print(f'* lines: {entry[\"lines\"]}')\n",
    "        print('')\n",
    "\n",
    "        data = response\n",
    "        entries.append(entry)\n",
    "\n",
    "    return pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = \"Generate a list of exactly 100 random facts.  Don't add any additional text, just output the list.\"\n",
    "\n",
    "data = complete_chat(\n",
    "    list_prompt, seed=42, temperature=1.0, model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print(len(data.split('\\n')))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "iterations = 50\n",
    "\n",
    "def make_run_name(config):\n",
    "    return f\"{config['prompt'].split('')[0]}-run-{config['model']}_{config['seed']}_{config['temperature']}\"\n",
    "\n",
    "dfs = []\n",
    "for temperature in [0.0, 0.5, 1.0, 2.0]:\n",
    "    for model in ['gpt-4o', 'gpt-3.5-turbo']:\n",
    "        for prompt in ['Summarize the following: ', 'Rephrase the following: ']:\n",
    "            config = {\n",
    "                \"prompt\": prompt,\n",
    "                \"seed\": seed,\n",
    "                \"temperature\": temperature,\n",
    "                \"model\": model,\n",
    "                \"iterations\": iterations,\n",
    "            }\n",
    "            wandb.init(project=\"llm_fixed_point\",\n",
    "                       name=make_run_name(config),\n",
    "                       config=config)\n",
    "\n",
    "            df = run_list_summarize_experiment(data, prompt=\"\", **config)\n",
    "            dfs.append((config, df))\n",
    "\n",
    "            wandb.finish()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([x for _, x in dfs])\n",
    "df.to_csv('data/summarize_list.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_csv('data/summarize_list.csv')\n",
    "\n",
    "def compare(df, model, temperature):\n",
    "    df = df[(df.model == model) & (df.temperature == temperature)]['response']\n",
    "    print(df.iloc[0])\n",
    "    print('#' * 100)\n",
    "    print(df.iloc[-1])\n",
    "\n",
    "compare(df=read_df, model='gpt-4o', temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
